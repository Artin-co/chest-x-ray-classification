{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Info_Class:\n",
    "    def __init__(self, pathologies, class_weights, target_size, steps_per_epoch, validation_steps):\n",
    "        self.pathologies      = pathologies\n",
    "        self.class_weights    = class_weights\n",
    "        self.target_size      = target_size\n",
    "        self.steps_per_epoch  = steps_per_epoch\n",
    "        self.validation_steps = validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_up_dataframe(data, classes):\n",
    "    \"\"\" Label Structure\n",
    "        positive (exist):            1.0\n",
    "        negative (doesn't exist):   -1.0\n",
    "        Ucertain                     0.0\n",
    "        no mention                   NaN \"\"\"\n",
    "\n",
    "    # changing all no mention labels to negative\n",
    "    data = data[data['AP/PA']=='AP']\n",
    "    data = data[data['Frontal/Lateral']=='Frontal']\n",
    "    data = data.replace(np.nan,-1.0)\n",
    "\n",
    "    # appending the path to each sample\n",
    "    data = data[ ['Path'] + classes ]\n",
    "\n",
    "    for column in classes:\n",
    "        # data[column] = data[column].astype(int)\n",
    "        data[column] = data[column].replace(1,'pos')\n",
    "        data[column] = data[column].replace(-1,'neg')\n",
    "        data[column] = data[column].replace(0,'uncertain')\n",
    "        \n",
    "    return data\n",
    "\n",
    "def removing_uncertain_samples(data, pathologies):\n",
    "    \"\"\" Label Structure\n",
    "        positive (exist):            1.0\n",
    "        negative (doesn't exist):   -1.0\n",
    "        Ucertain                     0.0\n",
    "        no mention                   NaN \"\"\"\n",
    "                \n",
    "    for name in pathologies:\n",
    "        data = data.loc[data[name]!='uncertain']\n",
    "\n",
    "    # changing negative from -1.0 to 0.0\n",
    "    # data = data.replace(-1.0,0.0)\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathologies = [\"Enlarged Cardiomediastinum\" , \"Cardiomegaly\" , \"Lung Opacity\" , \"Lung Lesion\", \"Edema\" , \"Consolidation\" , \"Pneumonia\" , \"Atelectasis\" , \"Pneumothorax\" , \"Pleural Effusion\" , \"Pleural Other\" , \"Fracture\" , \"Support Devices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the raw table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sample-pruning\n",
      "train: (223414, 19)\n",
      "test: (234, 19)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Label Structure\n",
    "    positive (exist):            1.0\n",
    "    negative (doesn't exist):   -1.0\n",
    "    Ucertain                     0.0\n",
    "    no mention                   NaN \"\"\"\n",
    "\n",
    "\n",
    "# dir = '/Users/artinmac/GoogleDrive/RESEARCH/projects/Data7.chest_xray'\n",
    "dir = '/groups/jjrodrig/projects/chest/dataset/chexpert'\n",
    "train = pd.read_csv(dir + '/train.csv')\n",
    "test  = pd.read_csv(dir + '/valid.csv')\n",
    "\n",
    "print('before sample-pruning')\n",
    "print('train:',train.shape)\n",
    "print('test:',test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the pathologies of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cleaning_up_dataframe(train, pathologies)\n",
    "test  = cleaning_up_dataframe(test, pathologies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a few cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.iloc[:1000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separating the uncertain samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uncertain = train.copy()\n",
    "for name in pathologies:\n",
    "    train = train.loc[train[name]!='uncertain']\n",
    "    \n",
    "train_uncertain = train_uncertain.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting train/validatiion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after sample-pruning\n",
      "train (certain): (77894, 14)\n",
      "train (uncertain): (64223, 14)\n",
      "valid: (19473, 14)\n",
      "test: (169, 14)\n"
     ]
    }
   ],
   "source": [
    "valid = train.sample(frac=0.2)\n",
    "train = train.drop(valid.index)\n",
    "\n",
    "print('after sample-pruning')\n",
    "print('train (certain):',train.shape)\n",
    "print('train (uncertain):',train_uncertain.shape)\n",
    "print('valid:',valid.shape)\n",
    "print('test:',test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = len(pathologies)\n",
    "class_weights = np.ones(L)/L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "target_size =  (224,224) # (64,64)  #\n",
    "class_mode='raw'\n",
    "color_mode = 'rgb'\n",
    "y_col = list(pathologies) #'disease_vector'\n",
    "batch_size=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77894 validated image filenames.\n",
      "Found 19473 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = generator.flow_from_dataframe(dataframe=train, x_col='Path', y_col=y_col,color_mode=color_mode,directory=dir, target_size=target_size, batch_size=10000, class_mode=class_mode, shuffle=False)\n",
    "\n",
    "valid_generator = generator.flow_from_dataframe(dataframe=valid, x_col='Path', y_col=y_col,color_mode=color_mode,directory=dir, target_size=target_size, batch_size=10000, class_mode=class_mode, shuffle=False)  \n",
    "\n",
    "(x_train, y_train) = next(train_generator)\n",
    "steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().batch(batch_size)\n",
    "\n",
    "\n",
    "(x_valid, y_valid) = next(valid_generator)\n",
    "validation_steps = int(x_valid.shape[0]/batch_size)\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)) \n",
    "valid_data = valid_data.repeat().batch(batch_size)\n",
    "\n",
    "Info = Info_Class(pathologies, class_weights, target_size, steps_per_epoch, validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 169 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator = generator.flow_from_dataframe(dataframe=test, x_col='Path', y_col=y_col,color_mode=color_mode,directory=dir, target_size=target_size, batch_size=1, class_mode=class_mode, shuffle=False)\n",
    "\n",
    "Info = Info_Class(pathologies, class_weights, target_size, '', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('mlflow-xray': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0dd998473dbd4892f34807bf19aeea9c12a70ba84b1a5d02d168816cec7a7d398"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "dd998473dbd4892f34807bf19aeea9c12a70ba84b1a5d02d168816cec7a7d398"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
